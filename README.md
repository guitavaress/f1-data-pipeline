# ğŸï¸ F1 Data Pipeline

Este projeto Ã© um pipeline de dados simples para coletar, transformar e carregar dados de voltas de corrida da FÃ³rmula 1 usando Airflow, dbt e PostgreSQL. Ele demonstra uma arquitetura de dados em camadas (`raw`, `staging`, `marts`) para garantir a organizaÃ§Ã£o e a qualidade dos dados.

-----

### **VisÃ£o Geral da Arquitetura**

O pipeline utiliza a seguinte arquitetura:

  * **Fonte de Dados**: A biblioteca Python `FastF1` Ã© usada para extrair dados brutos de voltas de corrida da F1.
  * **IngestÃ£o de Dados**: Apache Airflow gerencia a orquestraÃ§Ã£o do pipeline, executando a ingestÃ£o dos dados para o banco de dados.
  * **Armazenamento de Dados**: PostgreSQL armazena os dados em diferentes esquemas, representando cada etapa da transformaÃ§Ã£o.
  * **TransformaÃ§Ã£o de Dados**: dbt (Data Build Tool) Ã© usado para transformar os dados brutos em modelos prontos para anÃ¡lise, seguindo a arquitetura em camadas (`raw`, `staging`, `marts`).
  * **OrquestraÃ§Ã£o**: Apache Airflow Ã© responsÃ¡vel por agendar e executar as tarefas de ingestÃ£o e transformaÃ§Ã£o.

-----

### **Estrutura do Projeto**

```
f1-data-pipeline/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ fastf1_load.py              # DefiniÃ§Ã£o do pipeline do Airflow
â”œâ”€â”€ f1_transform/                   # Projeto dbt para transformaÃ§Ã£o dos dados
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â””â”€â”€ stg_laps.sql        # Limpeza e preparaÃ§Ã£o dos dados
â”‚   â”‚   â””â”€â”€ marts/
â”‚   â”‚       â””â”€â”€ agg_laps.sql        # Modelo final para anÃ¡lise
â”‚   â”œâ”€â”€ macros/
â”‚   â”‚   â””â”€â”€ schema_macros.sql       # Macro para controle dos esquemas
â”œâ”€â”€ docker-compose.yml              # ConfiguraÃ§Ã£o dos serviÃ§os (Airflow, Postgres)
â”œâ”€â”€ Dockerfile.airflow              # Define o ambiente do Airflow
â””â”€â”€ README.md
```

-----

### **Como Usar**

#### **1. PrÃ©-requisitos**

Certifique-se de ter o Docker e o Docker Compose instalados em sua mÃ¡quina.

#### **2. ConfiguraÃ§Ã£o do Ambiente**

Clone este repositÃ³rio e navegue atÃ© a pasta do projeto.

```bash
git clone <URL_DO_SEU_REPOSITORIO>
cd f1-data-pipeline
```

#### **3. ExecuÃ§Ã£o dos ServiÃ§os**

Inicie os contÃªineres do Docker:

```bash
docker-compose up --build
```

O contÃªiner do Airflow iniciarÃ¡, e vocÃª poderÃ¡ acessar a UI do Airflow em `http://localhost:8080`. Use as credenciais `admin` para o usuÃ¡rio e senha.

#### **4. VerificaÃ§Ã£o**

No Airflow, a DAG chamada `f1_pipeline` deve estar visÃ­vel e pronta para ser executada. Dispare a DAG manualmente para iniciar o pipeline.

Ao concluir, vocÃª pode verificar os esquemas e tabelas no seu banco de dados PostgreSQL usando uma ferramenta como o DBeaver. VocÃª verÃ¡ as seguintes tabelas criadas:

  * `raw.fastf1_laps`
  * `staging.stg_laps`
  * `marts.agg_laps`

-----

### **Detalhes TÃ©cnicos**

#### **Arquivos de ConfiguraÃ§Ã£o**

  * **`docker-compose.yml`**: Configura os serviÃ§os `postgres` e `airflow`, montando os diretÃ³rios do projeto para que o Airflow possa acessÃ¡-los.
  * **`f1_transform/dbt_project.yml`**: Define o projeto dbt, as camadas (`staging`, `marts`) e o materializado das tabelas.
  * **`f1_transform/profiles.yml`**: Armazena as credenciais de conexÃ£o com o banco de dados. Ã‰ um arquivo de configuraÃ§Ã£o sensÃ­vel.
  * **`f1_transform/macros/schema_macros.sql`**: ContÃ©m uma macro personalizada que garante que os esquemas (`staging`, `marts`) sejam criados sem o prefixo padrÃ£o do dbt, evitando problemas de concatenaÃ§Ã£o.

#### **DAG `fastf1_load.py`**

A DAG Ã© dividida em trÃªs tarefas principais:

1.  **`create_schemas`**: Cria os esquemas `raw`, `staging` e `marts` no PostgreSQL antes de qualquer operaÃ§Ã£o.
2.  **`ingest_data`**: Coleta os dados de uma corrida da F1 e os carrega para a tabela `raw.fastf1_laps`.
3.  **`transform_data`**: Uma tarefa do Cosmos que executa o projeto dbt, transformando os dados de `raw` para `staging` e depois para `marts`.