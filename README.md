
# ğŸï¸ F1 Analytics Pipeline com Airflow, FastF1, Postgres e dbt

Este projeto implementa um pipeline de dados para coletar, armazenar e transformar dados da FÃ³rmula 1 utilizando:

- [Apache Airflow](https://airflow.apache.org/) como orquestrador
- [FastF1](https://theoehrly.github.io/Fast-F1/) para ingestÃ£o dos dados
- [PostgreSQL](https://www.postgresql.org/) como data warehouse
- [dbt](https://www.getdbt.com/) para transformaÃ§Ãµes analÃ­ticas

---

## ğŸ“ Estrutura do Projeto

```bash
.
â”œâ”€â”€ dags/                    # DAGs do Airflow
â”‚   â”œâ”€â”€ fastf1_load.py       # DAG principal para ingestÃ£o FastF1
â”‚   â””â”€â”€ load_fastf1.py       # Script de ingestÃ£o com FastF1
â”œâ”€â”€ cache/                   # Cache local usado pelo FastF1
â”œâ”€â”€ dbt/                     # DiretÃ³rio de modelos dbt
â”œâ”€â”€ scripts/                 # Scripts auxiliares, se necessÃ¡rio
â”œâ”€â”€ Dockerfile.airflow       # Dockerfile customizado para Airflow
â”œâ”€â”€ docker-compose.yml       # ConfiguraÃ§Ã£o de todos os serviÃ§os
â”œâ”€â”€ profiles.yml             # Perfil do dbt para conexÃ£o com o Postgres
â””â”€â”€ README.md                # Este arquivo
```

---

## ğŸš€ Como Executar Localmente

### 1. PrÃ©-requisitos

- Docker e Docker Compose instalados
- Porta `8080` (Airflow) e `5432` (Postgres) disponÃ­veis

### 2. Clonar o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/seu-repo.git
cd seu-repo
```

### 3. Criar as pastas necessÃ¡rias

```bash
mkdir -p ./cache ./scripts
```

> ğŸ”’ A pasta `./cache` Ã© usada pelo FastF1 como diretÃ³rio de cache e precisa ter permissÃ£o de escrita.

### 4. Subir os containers

```bash
docker-compose up -d --build
```

### 5. Acessar o Airflow

Abra [http://localhost:8080](http://localhost:8080) no navegador.

- **UsuÃ¡rio**: `admin`
- **Senha**: `admin`

---

## ğŸ› ï¸ DAG Principal

- **Nome**: `fastf1_to_postgres`
- **FunÃ§Ã£o**: coleta dados da FÃ³rmula 1 via `FastF1` e insere no banco Postgres

---

## ğŸ§  TransformaÃ§Ãµes com dbt

O serviÃ§o `dbt` roda os modelos a partir do diretÃ³rio `./dbt`, com configuraÃ§Ã£o em `profiles.yml`.

Para executar os modelos manualmente:

```bash
docker-compose run --rm dbt run
```

---

## âš™ï¸ ConfiguraÃ§Ãµes TÃ©cnicas

### docker-compose.yml

Inclui os seguintes serviÃ§os:

- **Postgres**: base de dados para armazenamento
- **Airflow**: orquestrador das DAGs
- **dbt**: ferramenta para transformaÃ§Ã£o de dados

Volumes montados:

```yaml
volumes:
  - ./dags:/opt/airflow/dags
  - ./cache:/opt/airflow/cache
  - ./scripts:/opt/airflow/dags
```

### Airflow Cache com FastF1

O script `load_fastf1.py` ativa o cache no caminho:

```python
fastf1.Cache.enable_cache("/opt/airflow/cache")
```

---

## ğŸ§ª Testes

VocÃª pode rodar a DAG manualmente na interface do Airflow ou configurar uma agenda para execuÃ§Ãµes automÃ¡ticas.

---

## ğŸ§¹ Dicas de Debug

- Se a DAG nÃ£o aparecer: verifique a extensÃ£o `.py` dos arquivos dentro de `dags/` e reinicie o Airflow.
- Se der erro de cache: verifique permissÃµes da pasta `./cache` e se ela foi criada corretamente.

---

## ğŸ“Œ Roadmap Futuro

- Armazenamento histÃ³rico por temporada
- CriaÃ§Ã£o de materializaÃ§Ãµes dbt (`incremental` e `view`)
- ConexÃ£o com ferramentas de BI (ex: Metabase ou Superset)

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

---

## ğŸ‘¨â€ğŸ’» Autor

Guilherme Tavares  
[LinkedIn](https://www.linkedin.com/in/seu-perfil) â€¢ [GitHub](https://github.com/seu-usuario)
